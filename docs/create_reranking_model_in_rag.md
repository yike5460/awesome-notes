## Re-ranking model usage
The re-ranking model is used to balance the trade-off between relevance (how well documents match the query) and diversity (how different the selected documents are from each other). This ensures that the final set of documents provided to the LLM covers a broad aspect of the query, enhancing the model's ability to generate accurate and comprehensive responses. 
Common case are integrating BM25 and cosine similarity scores, the reranking model can refine the initial retrieval results to prioritize documents that are not only semantically related to the query (as indicated by cosine similarity) but also contain a high frequency of the query terms (as indicated by BM25), address the non-linear relationship between BM25 and cosine similarity scores since these scores may not be directly comparable or linearly separable, the reranking model can effectively combine them in a way that optimizes the final document selection. And user can adjust the weights assigned to BM25 and cosine similarity scores in the reranking model to favor either term-based relevance or semantic similarity, depending on the actual use case.